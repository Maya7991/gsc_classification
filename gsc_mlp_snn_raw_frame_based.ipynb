{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Let's try framed raw audio on MLP\n",
        "\n",
        "Model is not learning anything! \\\n",
        "I thought this model would be emulating conv1D by dividing the data into frames."
      ],
      "metadata": {
        "id": "qNdcaIvzDRp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch --quiet\n",
        "!pip install torchaudio --quiet"
      ],
      "metadata": {
        "id": "wnnQZkNKPgI6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchaudio\n",
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "from snntorch import spikegen, surrogate, functional as SF\n",
        "import snntorch as snn"
      ],
      "metadata": {
        "id": "MA7BCq3vEmxF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Frame the Audio Data\n",
        "\n",
        "* Sampling Rate: The original Speech Commands dataset has a sampling rate of 16,000 Hz. In this script, we resample it to 8,000 Hz to reduce computational load.\n",
        "\n",
        "* Normalization: Normalizing each frame helps in stabilizing the training process, especially when dealing with raw audio inputs.​\n",
        "\n",
        "* Label Mapping: The script builds a label-to-index mapping to convert string labels into integer indices suitable for training.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ecOKz9iFEuwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 400 features per timestep\n",
        "* 20 timesteps\n",
        "* total features in 1 second = 400 * 20 = 8000"
      ],
      "metadata": {
        "id": "mqQdN411G-sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "F8lj0mbePwTb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxfi86q1l3_x",
        "outputId": "19de36d6-56cd-485a-be52-471fe67317b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.26G/2.26G [00:24<00:00, 101MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0:\n",
            "Frames shape: torch.Size([64, 20, 400])\n",
            "Labels shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        " # Custom dataset class to handle framing\n",
        "class FramedSpeechCommands(Dataset):\n",
        "    def __init__(self, subset):\n",
        "        self.dataset = SPEECHCOMMANDS(root=\"./\", download=True, subset=subset)\n",
        "        self.resample = torchaudio.transforms.Resample(orig_freq=16000, new_freq=8000)\n",
        "        self.frame_size = 400  # 400 samples per frame\n",
        "        self.num_frames = 20   # 8000 samples / 400 = 20 frames per 1-second clip\n",
        "        self.label_to_index = self._build_label_index()\n",
        "\n",
        "    def _build_label_index(self):\n",
        "        labels = sorted(set(datapoint[2] for datapoint in self.dataset))\n",
        "        return {label: idx for idx, label in enumerate(labels)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        waveform, sample_rate, label, *_ = self.dataset[idx]\n",
        "        waveform = self.resample(waveform)\n",
        "        waveform = waveform.squeeze(0)  # Convert from [1, N] to [N]\n",
        "\n",
        "        # Ensure the waveform is exactly 8000 samples\n",
        "        if waveform.size(0) < 8000:\n",
        "            padding = 8000 - waveform.size(0)\n",
        "            waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
        "        else:\n",
        "            waveform = waveform[:8000]\n",
        "\n",
        "        # Frame the waveform into segments of 400 samples\n",
        "        frames = waveform.unfold(0, self.frame_size, self.frame_size)  # Shape: [20, 400]\n",
        "\n",
        "        # Normalize each frame\n",
        "        frames = (frames - frames.mean(dim=1, keepdim=True)) / (frames.std(dim=1, keepdim=True) + 1e-5)\n",
        "\n",
        "        label_idx = self.label_to_index[label]\n",
        "        return frames, label_idx\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = FramedSpeechCommands(subset='training')\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Example: Iterate through the DataLoader\n",
        "for batch_idx, (frames, labels) in enumerate(train_loader):\n",
        "    # frames shape: [batch_size, 20, 400]\n",
        "    # labels shape: [batch_size]\n",
        "    print(f\"Batch {batch_idx}:\")\n",
        "    print(f\"Frames shape: {frames.shape}\")\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "    break  # Remove this break to iterate through the entire dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP SNN Network"
      ],
      "metadata": {
        "id": "CsK2NqCTPNjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. MLP-SNN Model\n",
        "beta = 0.95\n",
        "# spike_grad = surrogate.fast_sigmoid()\n",
        "\n",
        "class MLP_SNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.lif1 = snn.Leaky(beta=0.95)\n",
        "\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.lif2 = snn.Leaky(beta=0.95)\n",
        "\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "        self.lif3 = snn.Leaky(beta=0.95)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "        spk_out = []\n",
        "\n",
        "        for t in range(x.size(0)):\n",
        "            x_t = x[t]\n",
        "            cur1 = self.fc1(x_t)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "            cur3 = self.fc3(spk2)\n",
        "            spk3, mem3 = self.lif3(cur3, mem3)\n",
        "\n",
        "            spk_out.append(spk3)\n",
        "\n",
        "        return torch.stack(spk_out, dim=0)\n"
      ],
      "metadata": {
        "id": "rf9ouNuZPPy6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "YM9ltl46P7KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = SF.ce_rate_loss()\n",
        "num_epochs = 10\n",
        "\n",
        "# 4. Training\n",
        "def train():\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        acc = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            # print(inputs.shape) # shape: [B, T, F]\n",
        "            inputs = inputs.permute(1, 0, 2).float().to(device)  # shape: [T, B, F]\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            # print(f\"outputs {outputs.shape}\")\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            acc += SF.accuracy_rate(outputs, labels)\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        avg_acc = 100 * acc / len(train_loader)\n",
        "        print(f\"--------Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.2f}%--------\")\n"
      ],
      "metadata": {
        "id": "pOFv0FCqP99Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_dataset.label_to_index)\n",
        "model = MLP_SNN(input_size=400, output_size=num_classes).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "u2jA1vL4QlOj",
        "outputId": "7571d048-0014-4b10-a038-c23657c71885"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------Epoch 1/10, Loss: 3.5558, Accuracy: 2.16%--------\n",
            "--------Epoch 2/10, Loss: 3.5554, Accuracy: 2.17%--------\n",
            "--------Epoch 3/10, Loss: 3.5546, Accuracy: 2.44%--------\n",
            "--------Epoch 4/10, Loss: 3.5536, Accuracy: 2.45%--------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-71696a201315>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP_SNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-f09b7116c2b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "ifXdysYzTW4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.permute(1, 0, 2).float().to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.mean(0).max(1)  # Mean over time, shape [B, num_classes]\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "w0v14fIaTWSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}