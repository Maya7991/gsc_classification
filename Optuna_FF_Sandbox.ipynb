{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f21f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "33820c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import sys\n",
    "#new\n",
    "import itertools\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ba361092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F  \n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1f675773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "from progress_table import ProgressTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47bda401",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "def MNIST_loaders(device, args):\n",
    "\n",
    "    # From cnn_mnist2.py:\n",
    "    transform=Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    ######################\n",
    "    data = MNIST(\"./data/\", train=True,\n",
    "                download=True,\n",
    "                transform=transform)\n",
    "    data.data.to(device)\n",
    "    data.targets.to(device)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        data,\n",
    "        batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    test = MNIST('./data/', train=False,\n",
    "                download=True,\n",
    "                transform=transform)\n",
    "    test.data.to(device)\n",
    "    test.targets.to(device)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test,\n",
    "        batch_size=args.test_batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feecd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer classes\n",
    "\n",
    "class Conv_layer(nn.Conv2d): \n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, lr=0.05,\n",
    "                bias=True, device=DEVICE, dtype=None): # original: bias=True\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, padding, bias=bias, device=device, dtype=dtype)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.opt = Adam(self.parameters(), lr=lr)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_direction = x / (x.norm(2, (1,2,3), keepdim=True) + 1e-4)\n",
    "        x = self.relu(self.conv(x_direction))\n",
    "        #x = self.maxpool(x)\n",
    "        return x\n",
    "            \n",
    "    def layer_train(self, x_pos, x_neg, threshold=2.0, do_step=0):          \n",
    "        conv_pos3d = self.forward(x_pos)\n",
    "        conv_neg3d = self.forward(x_neg)\n",
    "        conv_pos1d = self.flatten(conv_pos3d) \n",
    "        conv_neg1d = self.flatten(conv_neg3d)\n",
    "        g_pos = conv_pos1d.pow(2).mean(1)\n",
    "        g_neg = conv_neg1d.pow(2).mean(1)\n",
    "        # The following loss pushes pos (neg) samples to\n",
    "        # values larger (smaller) than the self.threshold.\n",
    "        loss = torch.log(1 + torch.exp(torch.cat([\n",
    "            -g_pos + threshold,\n",
    "            g_neg - threshold]))).mean()\n",
    "        self.opt.zero_grad()\n",
    "        # this backward just compute the derivative and hence\n",
    "        # is not considered backpropagation.\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
    "    \n",
    "class FC_layer(nn.Linear): \n",
    "    def __init__(self, in_features, out_features,\n",
    "                bias=True, device=DEVICE, dtype=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.opt = Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n",
    "        return self.relu(\n",
    "            torch.mm(x_direction, self.weight.T) +\n",
    "            self.bias.unsqueeze(0))\n",
    "\n",
    "    def layer_train(self, x_pos, x_neg, threshold):\n",
    "        g_pos = self.forward(x_pos).pow(2).mean(1)\n",
    "        g_neg = self.forward(x_neg).pow(2).mean(1)\n",
    "        # The following loss pushes pos (neg) samples to\n",
    "        # values larger (smaller) than the self.threshold.\n",
    "        loss = torch.log(1 + torch.exp(torch.cat([\n",
    "            -g_pos + threshold,\n",
    "            g_neg - threshold]))).mean()\n",
    "        self.opt.zero_grad()\n",
    "        # this backward just compute the derivative and hence\n",
    "        # is not considered backpropagation.\n",
    "        loss.backward(retain_graph=True)\n",
    "        self.opt.step()\n",
    "        \n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
    "\n",
    "# class Linear_Classifier(nn.Linear):\n",
    "#     def __init__(self, in_features, out_features, lr,\n",
    "#                 bias=False, device=DEVICE, dtype=None):\n",
    "#         super().__init__(in_features, out_features, bias, device, dtype)\n",
    "#         self.linear_classi = nn.Linear(in_features, out_features, bias=False)\n",
    "#         self.opt = Adam(self.parameters(), lr=lr)\n",
    "#         self.classification_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n",
    "#         x = self.linear_classi(x.detach())\n",
    "#         return x\n",
    "\n",
    "#     def layer_train(self, x, y):    \n",
    "#         output = self.forward(x)\n",
    "#         output = output - torch.max(output, dim=-1, keepdim=True)[0]\n",
    "#         loss = self.classification_loss(output, y)   \n",
    "#         self.opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         self.opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna: Learning rate setting\n",
    "\n",
    "def get_lr_scheduler(optimizer, params):\n",
    "            if params[\"lr_decay\"] == \"exp_decay\":\n",
    "                return torch.optim.lr_scheduler.ExponentialLR(\n",
    "                    optimizer=optimizer,\n",
    "                    gamma=0.8,\n",
    "                )\n",
    "            elif params[\"lr_decay\"] == \"cosine_decay\":\n",
    "                return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    optimizer=optimizer,\n",
    "                    T_max=EPOCHS * STEPS_PER_EPOCH,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9742217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna: Optimizer Setting\n",
    "\n",
    "def get_optimizer(model,params):\n",
    "    # We optimize the choice of optimizers as well as their parameters.\n",
    "\n",
    "    if params[\"opt\"] == \"Adam\":\n",
    "        return torch.optim.Adam(model.parameters(),\n",
    "                                lr=params[\"lr_init\"])\n",
    "    elif params[\"opt\"] == \"SGD\":\n",
    "        return torch.optim.SGD(model.parameters(),\n",
    "                                lr=params[\"lr_init\"], \n",
    "                                momentum=params[\"opt.sgd.moment\"],\n",
    "                                nesterov=params[\"opt.sgd.nesterov\"])\n",
    "    elif params[\"opt\"] == \"RMSprop\":\n",
    "        return torch.optim.RMSprop(model.parameters(),\n",
    "                                    lr=params[\"lr_init\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna: Model definition\n",
    "\n",
    "class Net_FF_Conv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, epochs, batch_size, params):\n",
    "        super().__init__()\n",
    "        self.num_epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = 0.01 # in kaggle it is 0.001\n",
    "        self.threshold = 10.0\n",
    "        self.outchns = 0\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.model = self.Model(params)\n",
    "        #self.linear_classifier = Linear_Classifier(10, 10, self.lr, bias=False)\n",
    "\n",
    "        self.classification_loss = nn.CrossEntropyLoss()\n",
    "        self.opt = params[\"opt\"]\n",
    "        self.scheduler = params[\"lr_decay\"]\n",
    "        \n",
    "    def Model(params):\n",
    "        \n",
    "        structure = 1\n",
    "        FFDNN = []\n",
    "        outchn_layer = []\n",
    "        \n",
    "        in_v_size = params[\"input_dim_v\"]\n",
    "        in_h_size = params[\"input_dim_h\"]\n",
    "        in_chn = params[\"input_chn\"]\n",
    "        out_v_size = in_v_size\n",
    "        out_h_size = in_h_size\n",
    "        out_chn = in_chn\n",
    "\n",
    "        #############################################################################################################\n",
    "        \n",
    "        stopped = 0\n",
    "        for i in range(params[\"level\"]):\n",
    "            if structure:\n",
    "                print(\"in_size: (\", in_v_size,\",\",in_h_size,\",\",in_chn,\")\")\n",
    "            if (params[\"kernel_ff {}\".format(i)] > 1) & (params[\"stride_ff {}\".format(i)] > 1) & (params[\"kernel_ff {}\".format(i)] + params[\"stride_ff {}\".format(i)] > in_v_size):\n",
    "                print(\"Model gen - layer \",params[\"level\"],\": Kernel + stride (\",params[\"kernel_ff {}\".format(i)],\" + \",params[\"stride_ff {}\".format(i)],\") is larger than in_v_size=\",in_v_size,\":\")\n",
    "                while (params[\"kernel_ff {}\".format(i)] > 1) & (params[\"stride_ff {}\".format(i)] > 1) & (params[\"kernel_ff {}\".format(i)] + params[\"stride_ff {}\".format(i)] > in_v_size):\n",
    "                    if params[\"kernel_ff {}\".format(i)] > params[\"stride_ff {}\".format(i)]:\n",
    "                        params[\"kernel_ff {}\".format(i)] = params[\"kernel_ff {}\".format(i)] - 1\n",
    "                    else:\n",
    "                        params[\"stride_ff {}\".format(i)] = params[\"stride_ff {}\".format(i)] - 1\n",
    "                print(\"    -> Reducing them to Kernel + stride = \",params[\"kernel_ff {}\".format(i)],\" + \",params[\"stride_ff {}\".format(i)])\n",
    "            if (params[\"kernel_ff {}\".format(i)] > 1) & (params[\"stride_ff {}\".format(i)] > 1) & (params[\"kernel_ff {}\".format(i)] + params[\"stride_ff {}\".format(i)] > in_h_size):\n",
    "                print(\"Model gen - layer \",params[\"level\"],\": Kernel + stride (\",params[\"kernel_ff {}\".format(i)],\" + \",params[\"stride_ff {}\".format(i)],\") is larger than in_h_size=\",in_h_size,\":\")\n",
    "                while (params[\"kernel_ff {}\".format(i)] > 1) & (params[\"stride_ff {}\".format(i)] > 1) & (params[\"kernel_ff {}\".format(i)] + params[\"stride_ff {}\".format(i)] > in_h_size):\n",
    "                    if params[\"kernel_ff {}\".format(i)] > params[\"stride_ff {}\".format(i)]:\n",
    "                        params[\"kernel_ff {}\".format(i)] = params[\"kernel_ff {}\".format(i)] - 1\n",
    "                    else:\n",
    "                        params[\"stride_ff {}\".format(i)] = params[\"stride_ff {}\".format(i)] - 1\n",
    "                print(\"    -> Reducing them to Kernel + stride = \",params[\"kernel_ff {}\".format(i)],\" + \",params[\"stride_ff {}\".format(i)])\n",
    "            out_v_size = int((in_v_size + 2 - params[\"kernel_ff {}\".format(i)])/params[\"stride_ff {}\".format(i)]) +1\n",
    "            out_h_size = int((in_h_size + 2 - params[\"kernel_ff {}\".format(i)])/params[\"stride_ff {}\".format(i)]) +1\n",
    "            out_chn = params[\"filter_ff {}\".format(i)]\n",
    "            if (out_v_size <= 2) | (out_h_size <= 2):\n",
    "                stopped = i\n",
    "                out_v_size = in_v_size\n",
    "                out_h_size = in_h_size \n",
    "                out_chn = in_chn\n",
    "                break\n",
    "            in_v_size = out_v_size\n",
    "            in_h_size = out_h_size\n",
    "            in_chn = out_chn\n",
    "            if i == 0:\n",
    "                FFDNN.append(Conv_layer(in_channels=params[\"input_chn\"],\n",
    "                                out_channels=params[\"filter_ff {}\".format(i)], \n",
    "                                kernel_size=(params[\"kernel_ff {}\".format(i)],params[\"kernel_ff {}\".format(i)]),\n",
    "                                stride=params[\"stride_ff {}\".format(i)],\n",
    "                                padding=1))\n",
    "            else:\n",
    "                FFDNN.append(Conv_layer(in_channels=params[\"filter_ff {}\".format(i-1)],\n",
    "                                out_channels=params[\"filter_ff {}\".format(i)], \n",
    "                                kernel_size=(params[\"kernel_ff {}\".format(i)],params[\"kernel_ff {}\".format(i)]),\n",
    "                                stride=params[\"stride_ff {}\".format(i)],\n",
    "                                padding=1))\n",
    "            outchn_layer.append(out_v_size*out_h_size*out_chn)                \n",
    "            if structure:\n",
    "                print(\"  out_size (cnn): (\", out_v_size,\",\",out_h_size,\",\",out_chn,\")\")\n",
    "            #print(FFDNN)\n",
    "            \n",
    "        if stopped:\n",
    "            print(\"Model gen - layer \",i,\": The model has been reduced too far, stopping feature extractor at level=\", i - 1)\n",
    "            params[\"level\"] = stopped\n",
    "\n",
    "        FFDNN.append(nn.Linear(np.sum(outchn_layer),params[\"classes\"],bias=False))\n",
    "        \n",
    "        return nn.Sequential(*FFDNN)\n",
    "    \n",
    "    def predict_FF(self, h_test, y_test):\n",
    "        self_model.eval()\n",
    "        pred_acc = []\n",
    "        for j in range(int(h_test.shape[0]/self.batch_size)):\n",
    "            x = h_test[j*self.batch_size:(j+1)*self.batch_size].to(DEVICE)\n",
    "            y = y_test[j*self.batch_size:(j+1)*self.batch_size].to(DEVICE)\n",
    "            h = self.flatten(x)\n",
    "            h = get_neutral_label_before_FC(h)            \n",
    "            input_classification_model = []\n",
    "            first_layer = 1\n",
    "            for layer in self.model:\n",
    "                h = layer(h)\n",
    "                if(first_layer==0):\n",
    "                    input_classification_model.append(h)\n",
    "                first_layer = 0   \n",
    "            input_classification_model = torch.concat(input_classification_model, dim=-1)\n",
    "            output = self.linear_classifier(input_classification_model.detach())\n",
    "            output = output - torch.max(output, dim=-1, keepdim=True)[0]\n",
    "            pred = output.argmax(1)\n",
    "            pred_acc.append(pred.eq(y).float().mean().item())\n",
    "        return sum(pred_acc) / len(pred_acc)\n",
    "        \n",
    "\n",
    "    def net_train_FF(self, h_train, y_train):\n",
    "        self.model.train()\n",
    "        for i in range(self.num_epochs):\n",
    "            for j in range(int(h_train.shape[0]/self.batch_size)):\n",
    "                x = h_train[j*self.batch_size:(j+1)*self.batch_size].to(DEVICE)\n",
    "                y = y_train[j*self.batch_size:(j+1)*self.batch_size].to(DEVICE)\n",
    "                x = self.flatten(x)\n",
    "                x_pos = overlay_y_on_x_before_FC(x, y).to(DEVICE)\n",
    "                rnd = torch.randperm(x.size(0)).to(DEVICE)\n",
    "                while(len(torch.where(y[rnd]==y)[0]) > 0):\n",
    "                    rnd[torch.where(rnd == (self.batch_size-1))] -= 10\n",
    "                    rnd[torch.where(y[rnd]==y)] += 1\n",
    "                x_neg = overlay_y_on_x_before_FC(x, y[rnd]).to(DEVICE)\n",
    "                \n",
    "                h_pos, h_neg = x_pos, x_neg\n",
    "                \n",
    "                for layer in self.model[:-1]:\n",
    "                    h_pos, h_neg = layer.layer_train(h_pos, h_neg, self.threshold)\n",
    "                    \n",
    "                # train linear classifier:\n",
    "                input_classification_model = []\n",
    "                h = get_neutral_label_before_FC(x)\n",
    "                nonfirst_layer = 0\n",
    "                for layer in self.model[:-1]:\n",
    "                    h = layer(h)\n",
    "                    if nonfirst_layer:\n",
    "                        input_classification_model.append(h)\n",
    "                    nonfirst_layer = 1  \n",
    "                input_classification_model = torch.concat(input_classification_model, dim=-1)\n",
    "                #self.linear_classifier.layer_train(input_classification_model, y)\n",
    "                output = self.model[end](input_classification_model, y)\n",
    "                output = output - torch.max(output, dim=-1, keepdim=True)[0]\n",
    "                \n",
    "                loss = self.classification_loss(output, y)   \n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna: Params definition\n",
    "\n",
    "def define_search_space(trial):\n",
    "    # Hyperparameters to be tuned by Optuna.\n",
    "    params = dict()\n",
    "    \n",
    "    params[\"input_dim_v\"] = trial.suggest_categorical(\"input_dim_v\", [28])\n",
    "    params[\"input_dim_h\"] = trial.suggest_categorical(\"input_dim_h\", [28])\n",
    "    params[\"input_chn\"] = trial.suggest_categorical(\"input_chn\", [1])\n",
    "    params[\"classes\"] = trial.suggest_categorical(\"classes\", [10])\n",
    "    \n",
    "    ### Optimizer\n",
    "    #params[\"opt\"] = trial.suggest_categorical(\"opt\", [\"SGD\"]) # default\n",
    "    params[\"opt\"] = trial.suggest_categorical(\"opt\", [\"Adam\"])\n",
    "    #params[\"opt\"] = trial.suggest_categorical(\"opt\", [\"Adam\", \"SGD\", \"RMSprop\"])\n",
    "    #params[\"opt.sgd.moment\"] = trial.suggest_categorical(\"opt.sgd.moment\", [0.9]) # default\n",
    "    #params[\"opt.sgd.moment\"] = trial.suggest_float(\"opt.sgd.moment\", 0.0, 1.0)\n",
    "    #params[\"opt.sgd.nesterov\"] = trial.suggest_categorical(\"opt.sgd.nesterov\", [True]) # default\n",
    "    \n",
    "    #params[\"lr_init\"] = trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True)\n",
    "    params[\"lr_init\"] = trial.suggest_categorical(\"lr_init\", [0.001])\n",
    "    #params[\"lr_init\"] = trial.suggest_categorical(\"lr_init\", [0.001, 0.0001, 0.00001])\n",
    "    #params[\"lr_decay\"] = trial.suggest_categorical(\"lr_decay\", [\"cosine_decay\"]) # default\n",
    "    params[\"lr_scheduler\"] = trial.suggest_categorical(\"lr_scheduler\", [True])\n",
    "    if params[\"lr_scheduler\"]:\n",
    "        params[\"lr_decay\"] = trial.suggest_categorical(\"lr_decay\", [\"exp_decay\"])\n",
    "    #params[\"lr_decay\"] = trial.suggest_categorical(\"lr_decay\", [\"None\",\"exp_decay\",\"cosine_decay\"])\n",
    "        \n",
    "    ### Model architecture\n",
    "    # Feature-Extractor\n",
    "    #params[\"level\"] = trial.suggest_categorical(\"level\", [1, 2, 3, 4, 5, 6, 7, 8])\n",
    "    #params[\"level\"] = trial.suggest_categorical(\"level\", [1, 2, 3, 4, 5])\n",
    "    #params[\"level\"] = trial.suggest_categorical(\"level\", [1, 2, 3, 4])\n",
    "    params[\"level\"] = trial.suggest_categorical(\"level\", [2, 3, 4])\n",
    "    #params[\"level\"] = trial.suggest_categorical(\"level\", [2])\n",
    "    for i in range(params[\"level\"]):\n",
    "        #params[\"filter_ff {}\".format(i)] = trial.suggest_categorical(\"filter_ff {}\".format(i), [8, 16, 32, 48, 64, 80, 96])\n",
    "        params[\"filter_ff {}\".format(i)] = trial.suggest_categorical(\"filter_ff {}\".format(i), [8, 16, 32, 48, 64])\n",
    "        #params[\"kernel_ff {}\".format(i)] = trial.suggest_categorical(\"kernel_ff {}\".format(i), [3, 5, 7, 9, 11, 13, 15])\n",
    "        #params[\"kernel_ff {}\".format(i)] = trial.suggest_categorical(\"kernel_ff {}\".format(i), [3, 5 , 7])\n",
    "        params[\"kernel_ff {}\".format(i)] = trial.suggest_categorical(\"kernel_ff {}\".format(i), [3, 5])\n",
    "        #params[\"stride_ff {}\".format(i)] = trial.suggest_categorical(\"stride_ff {}\".format(i), [1, 2, 3, 4, 5, 6, 7])\n",
    "        #params[\"stride_ff {}\".format(i)] = trial.suggest_categorical(\"stride_ff {}\".format(i), [1, 2, 3, 4])\n",
    "        params[\"stride_ff {}\".format(i)] = trial.suggest_categorical(\"stride_ff {}\".format(i), [1, 2])\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2409b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna: Ctrl flow\n",
    "\n",
    "def objective(trial, args):\n",
    "\n",
    "    params = define_search_space(trial)\n",
    "    \n",
    "    # Create tf.keras model instance.\n",
    "    model = Net_FF_Conv.Model(params).to(DEVICE)\n",
    "    \n",
    "    def print_attr (module):\n",
    "        if hasattr(module, \"bias\"):\n",
    "            print(\"module \", module,\" bias:\", hasattr(module, \"bias\"), end=\"\")\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                print(\" size:\", hasattr(module.bias, \"size\"), \" size = \", module.bias.size())\n",
    "            else:\n",
    "                print(\"\\n\")\n",
    "        else:\n",
    "            print(\"module \", module,\" has no bias\")\n",
    "    #model.apply(print_attr)\n",
    "    \n",
    "    #print(model)\n",
    "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
    "    \n",
    "    optimizer=get_optimizer(model, params)\n",
    "    if params[\"lr_scheduler\"]:\n",
    "        scheduler = get_lr_scheduler(optimizer, params)\n",
    "\n",
    "    # Create dataset instance.\n",
    "    train_loader, valid_loader = MNIST_loaders(DEVICE, args)\n",
    "\n",
    "    \n",
    "    # Training of the model.\n",
    "    for epoch in range(args.epochs):\n",
    "        print(\"epoch: \", epoch)\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            #print(\"    batch_idx, train: \", batch_idx)\n",
    "            #print(\"        data shape: \", data.size())\n",
    "            # Limiting training data for faster epochs.\n",
    "            #if batch_idx * args.batch_size >= args.batch_size * 30:\n",
    "                #print(\"    break\")\n",
    "            #    break\n",
    "\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            #---\n",
    "            # x_pos = overlay_y_on_x(data, target)\n",
    "            # rnd = torch.randperm(data.size(0)).to(DEVICE)\n",
    "            # while(len(torch.where(target[rnd]==target[0])[0]) > 0):\n",
    "            #     rnd[torch.where(rnd == (args.test_batch_size-1))] -= 10\n",
    "            #     rnd[torch.where(target[rnd]==target)] += 1\n",
    "            # x_neg = overlay_y_on_x(data, target[rnd])\n",
    "                \n",
    "            # h_pos, h_neg = x_pos, x_neg\n",
    "\n",
    "            # h_pos, h_neg = self.conv1.layer_train(h_pos, h_neg, self.threshold, do_step=0)\n",
    "            #----\n",
    "\n",
    "            #### EXTENSION!!! ####\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            #output = model(data)\n",
    "            output = model.net_train(data,target)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if params[\"lr_scheduler\"]:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        \n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                #print(\"    batch_idx, valid: \", batch_idx)\n",
    "                # Limiting validation data.\n",
    "                #if batch_idx * args.batch_size >= args.batch_size * 10:\n",
    "                #    break\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                \n",
    "                #output = model(data)\n",
    "                output = model.predict(data,target)\n",
    "                \n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), args.batch_size * 10)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        # if trial.should_prune():\n",
    "        #     raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0530f188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown= ['--f=/home/ralf/.local/share/jupyter/runtime/kernel-v3d15f8a0bd67b7609977f319af35feb3ac7cabe7b.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 19:07:40,747] A new study created in RDB with name: FF-Sandbox-Elaborate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n",
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n",
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n",
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n",
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n",
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n",
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n",
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n",
      "A new study created in RDB with name: FF-Sandbox-Elaborate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-12 19:07:41,131] Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_size: ( 28 , 28 , 1 )\n",
      "  out_size (cnn): ( 13 , 13 , 48 )\n",
      "in_size: ( 13 , 13 , 48 )\n",
      "  out_size (cnn): ( 7 , 7 , 64 )\n",
      "in_size: ( 7 , 7 , 64 )\n",
      "  out_size (cnn): ( 3 , 3 , 8 )\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n",
      "Trial 0 failed with parameters: {'input_dim_v': 28, 'input_dim_h': 28, 'input_chn': 1, 'classes': 10, 'opt': 'Adam', 'lr_init': 0.001, 'lr_scheduler': True, 'lr_decay': 'exp_decay', 'level': 3, 'filter_ff 0': 48, 'kernel_ff 0': 5, 'stride_ff 0': 2, 'filter_ff 1': 64, 'kernel_ff 1': 3, 'stride_ff 1': 2, 'filter_ff 2': 8, 'kernel_ff 2': 5, 'stride_ff 2': 2} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3214671/2995609934.py\", line 128, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
      "  File \"/tmp/ipykernel_3214671/1588416694.py\", line 20, in objective\n",
      "    summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
      "    model(*x)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/home/ralf/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-12 19:07:41,141] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n",
      "Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 166\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown=\u001b[39m\u001b[38;5;124m\"\u001b[39m, unknown)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Until here\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[126], line 128\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    119\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    120\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m    121\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39mstorage_name\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=150, timeout=600)\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=150)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=50)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=20)\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=300)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=400, args)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m show_result(study, best_model_view\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, best_model_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[126], line 128\u001b[0m, in \u001b[0;36mmain.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    119\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    120\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m    121\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39mstorage_name\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=150, timeout=600)\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=150)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=50)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=20)\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=300)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#study.optimize(objective, n_trials=400, args)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m show_result(study, best_model_view\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, best_model_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[125], line 20\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, args)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m\"\u001b[39m, module,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m has no bias\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#model.apply(print_attr)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#print(model)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_dim_v\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_dim_h\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m=\u001b[39mget_optimizer(model, params)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_scheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/proj_odl_pytorch_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (48x3 and 11320x10)"
     ]
    }
   ],
   "source": [
    "# Optuna: Result printout\n",
    "\n",
    "def show_result(study,best_model_view=False, best_model_train=False):\n",
    "    pruned_trials = study.get_trials(deepcopy=True, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=True, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"\\n========================== Statistics ==========================\")\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    best_trial = study.best_trial\n",
    "\n",
    "    print(\"  Number: \", best_trial.number)\n",
    "    print(\"  Value: \", best_trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "        \n",
    "        \n",
    "    print(\"\\nComplete trials:\")\n",
    "    for i, trial in enumerate(complete_trials):\n",
    "        print(\"    {0:2d} [{1:2d}] val={2:6.4f} -> \".format(i,trial.number,trial.value), end=\"\")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"{}: {} \".format(key,value), end=\"\")\n",
    "        print(\"\")\n",
    "        \n",
    "    print(\"\\nPruned trials:\")\n",
    "    for i, trial in enumerate(pruned_trials):\n",
    "        print(\"    {0:2d} [{1:2d}] val={2:6.4f} -> \".format(i,trial.number,trial.value), end=\"\")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"{}: {} \".format(key,value), end=\"\")\n",
    "        print(\"\")\n",
    "                \n",
    "        \n",
    "    if best_model_view:\n",
    "        params = best_trial.params\n",
    "        model = Model(params).to(DEVICE)\n",
    "        \n",
    "        print(\"\\n=========================== Summary ============================\")\n",
    "        summary(model, (1,params[\"input_dim_v\"],params[\"input_dim_h\"]))\n",
    "        print(\"\")\n",
    "    \n",
    "    optimizer=get_optimizer(model, params)\n",
    "    if params[\"lr_scheduler\"]:\n",
    "        scheduler = get_lr_scheduler(optimizer, params)\n",
    "\n",
    "    if best_model_train:\n",
    "        if not(best_model_view):\n",
    "            params = best_trial.params\n",
    "            model = Model(params).to(DEVICE)\n",
    "\n",
    "        train_loader, valid_loader = MNIST_loaders(DEVICE, args)\n",
    "        \n",
    "        # Train model.\n",
    "        print(\"\\n============================= Training Model =============================\")\n",
    "        for epoch in range(args.epochs):\n",
    "            print(\"epoch: \", epoch)\n",
    "            model.train()\n",
    "            correct = 0\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                \n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            if params[\"lr_scheduler\"]:\n",
    "                scheduler.step()\n",
    "                \n",
    "            accuracy = correct / min(len(train_loader.dataset), args.batch_size * 10)\n",
    "\n",
    "            trial.report(accuracy, epoch)\n",
    "\n",
    "        #plt.plot(history.history['accuracy'],color = 'blue', label = 'accuracy')\n",
    "        #plt.plot(history.history['val_accuracy'],color = 'red', label = 'val')\n",
    "        #plt.title('Model accuracy')\n",
    "        #plt.ylabel('Accuracy')\n",
    "        #plt.xlabel('Epoch')\n",
    "        #plt.legend\n",
    "        \n",
    "        print(\"\\n============================== Saving Model ==============================\")\n",
    "        torch.save(model, \"FF.best_model.pytorch\")\n",
    "        print(\"Saved model to disk\")\n",
    "        \n",
    "        # evaluate the model\n",
    "        print(\"\\n============================ Evaluating Model ============================\")\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), args.batch_size * 10)\n",
    "\n",
    "        print(\"Evaluation Accuracy:\")\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # Add stream handler of stdout to show the messages\n",
    "    optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "    study_name = \"FF-Sandbox-Elaborate\"  # Unique identifier of the study.\n",
    "    storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "    \n",
    "    if os.path.exists(\"{}.db\".format(study_name)):\n",
    "        optuna.delete_study(study_name=study_name, storage=storage_name)\n",
    "        \n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\", pruner=optuna.pruners.MedianPruner(n_startup_trials=2),\n",
    "        study_name=study_name, storage=storage_name\n",
    "    )\n",
    "\n",
    "    #study.optimize(objective, n_trials=150, timeout=600)\n",
    "    #study.optimize(objective, n_trials=150)\n",
    "    #study.optimize(objective, n_trials=50)\n",
    "    #study.optimize(objective, n_trials=20)\n",
    "    study.optimize(lambda trial: objective(trial, args), n_trials=2)\n",
    "    #study.optimize(objective, n_trials=300)\n",
    "    #study.optimize(objective, n_trials=400, args)\n",
    "\n",
    "    show_result(study, best_model_view=True, best_model_train=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=128, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--no-mps', action='store_true', default=False,\n",
    "                        help='disables macOS GPU training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    #parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "    #                    help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--log-interval', type=int, default=1, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    #args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    print(\"unknown=\", unknown)\n",
    "    # Until here\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b335d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f935367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"optuna-dashboard sqlite:///DCNN-Elaborate.db --port 8081 --host 0.0.0.0 &\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
