{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgA0tcLmZClixbeOnu1vI9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maya7991/gsc_classification/blob/main/gsc_mel_snn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "import snntorch.functional as SF\n"
      ],
      "metadata": {
        "id": "cSJvqHy2Z_12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWiZiR-oZoAi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class SubsetSC(SPEECHCOMMANDS):\n",
        "    def __init__(self, subset: str = None):\n",
        "        super().__init__(\"./\", download=True)\n",
        "        def load_list(filename):\n",
        "            with open(filename) as f:\n",
        "                return [os.path.join(self._path, line.strip()) for line in f]\n",
        "        if subset == \"validation\":\n",
        "            self._walker = load_list(self._path + \"/validation_list.txt\")\n",
        "        elif subset == \"testing\":\n",
        "            self._walker = load_list(self._path + \"/testing_list.txt\")\n",
        "        elif subset == \"training\":\n",
        "            excludes = load_list(self._path + \"/validation_list.txt\") + load_list(self._path + \"/testing_list.txt\")\n",
        "            excludes = set(excludes)\n",
        "            self._walker = [w for w in self._walker if w not in excludes]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = T.MelSpectrogram(sample_rate=16000, n_mels=64)\n",
        "\n",
        "def preprocess(waveform):\n",
        "    return transform(waveform).squeeze(0)  # Shape: [freq, time]\n"
      ],
      "metadata": {
        "id": "BXYW-gtGZsI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def encode_input(mel_spec, time_steps=100):\n",
        "    return SF.poisson(mel_spec, num_steps=time_steps)  # Shape: [time, freq, time]\n"
      ],
      "metadata": {
        "id": "-v6MtijuZwmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SNNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(64 * 32, 512)\n",
        "        self.lif1 = snn.Leaky(beta=0.95, spike_grad=surrogate.fast_sigmoid())\n",
        "        self.fc2 = nn.Linear(512, 35)  # 35 classes in speech commands\n",
        "        self.lif2 = snn.Leaky(beta=0.95, spike_grad=surrogate.fast_sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        spk2_rec = []\n",
        "\n",
        "        for step in range(x.size(0)):  # Time dimension\n",
        "            x_t = x[step]\n",
        "            cur1 = self.fc1(x_t.view(x_t.size(0), -1))\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            spk2_rec.append(spk2)\n",
        "\n",
        "        return torch.stack(spk2_rec)\n"
      ],
      "metadata": {
        "id": "vpUtFa02Zy6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train_batch(inputs, labels, model, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    spk_out = model(inputs)\n",
        "    out = spk_out.sum(dim=0)  # Sum over time\n",
        "    loss = loss_fn(out, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n"
      ],
      "metadata": {
        "id": "0TpWB8p-Z1wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, label in dataloader:\n",
        "            encoded = encode_input(preprocess(data))\n",
        "            spk_out = model(encoded)\n",
        "            pred = spk_out.sum(0).argmax(1)\n",
        "            correct += (pred == label).sum().item()\n",
        "            total += label.size(0)\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "O91zPnOlZ39r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}